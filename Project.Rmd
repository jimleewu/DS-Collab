---
title: "Tesla Supercharger Analysis"
author: "Jim-Lee Wu and Fion Huang"
subtitle: 
output:
  pdf_document:
    number_sections: true
  html_document:
    number_sections: true
  word_document: default
---

```{r}
library(tidyverse)
library(tidymodels)
library(rsample)
library(corrplot)
library(ranger)
library(glmnet)
library(kknn)
library(xgboost)
library(ggplot2)
```

# Introduction

There has been an increasing rise in popularity in electronic vehicles (EVs) throughout the past decade for its environmental, economic, and performance benefits. With so many EVs filling the streets, a need for a proper EV charging infrastructure is needed. Just like gasoline cars, EV drivers require charging stations where they can recharge when going long distances.

# Dataset

The data set that we will be working on in this project is called `tesla`. The data consist of all cities from highly populated counties in California. The counties in our data set consist of Alameda, Contra Costa, Fresno, Kern, Los Angeles, Orange, Riverside, Sacramento, San Diego, San Francisco, San Joaquin, San Mateo, Santa Barbara, Santa Clara, Stanislaus, and Ventura. We collected demographic data and Tesla Supercharging data for each city in the before mention counties.

## Parameters

`city` City

`county` County of City

`population` 2022 Population

`land_size` 2020 Land area in square miles

`medium_income` medium household income in 2018-2022 (in 2022 dollars)

`per_capita_income` per_capita_income: mean income of every person in 2018-2022 (in 2022 dollars)

`registered_voter` the number of registered voters (March 11, 2022)

`democratic` the number of registered voters declared as democratic (March 11, 2022)

`republican`the number of registered voters declared as republican (March 11, 2022)

`no_stations` the number of Tesla Supercharger stations

`mile` the number of stations that are less than one mile from a highway/freeway

`more_than_12` the number of stations that have more than 12 chargers

`no_v2`the number of V2 chargers

`no_urban` the number of urban chargers

`no_v3` the number of V3 chargers

`no_v4` the number of V4 chargers

`total` total number of chargers

## How The Data Was Collected

The data from this data set was gathered via various many online sources. When deciding on location, we wanted to focus on a state that we were familiar with so we chose California. When collecting data, we chose to only collect data from counties that had a population greater than 500,000. The reason we made this decision was because we wanted to focus more on higher populated counties. Our data set contains 16 counties and will contain 296 observations.

Counties have a combination of towns, unincorporated cities, and incorporated cities. In our data set, we are ONLY considering incorporated cities.

As for how the data was collected, the parameters:

`population`, `land_size`, `medium_income`, and `per_capita_income` were scraped from the [US Census](https://www.census.gov/quickfacts/). The following cities: Maricopa, Isleton, Indian Wells, Del Mar, Monte Sereno, Brisbane, Vernon, Rolling Hills, Irwindale, Industry, Hidden Hills, Bradbury, and Avalon were not found on the US Census so we scraped the demopgraphic data from the [Census Reporter](https://censusreporter.org/).

`registered_voter`, `democratic`, and `republican` were scraped from [Report of Registration](https://www.sos.ca.gov/elections/report-registration/88day-primary-2022). This data comes from the California Secretary of State and was reported on March 11, 2022.

`no_stations`, `more_than_12`, `no_v2`, `no_urban`, `no_v3`, `no_v4`, and `total` were scraped from [Supercharge.io](https://supercharge.info/changes), a community based forum centered on Tesla Supercharger data world-wide. The data we collected from Supercharge.io was done on April 30, 2024.

`mile` was self obtained from Google Maps using the "Measure Distance" feature. This distance was measured from each Tesla Supercharger station to the nearest highway/freeway enterance.

## Loading the data set

Lets load the data set and view it.

```{r}
tesla <- read.csv("Tesla Dataset.csv")
tesla <- tesla %>%
  mutate(county = as.factor(county))
tesla
```

## Exploratory Data Analysis


```{r}
tesla %>% 
  ggplot(aes(no_stations)) + 
  geom_bar(fill = "black") + 
  labs(title = "Distribution of Number of Stations")

tesla %>% 
  mutate(no_stations = as.factor(no_stations)) %>%
  mutate(no_stations = fct_lump_n(no_stations, n = 1, other_level = "1+ Stations",)) %>%
  ggplot(aes(no_stations)) + 
  geom_bar(fill = "black") + 
  labs(title = "Distribution of Number of Stations")
```

```{r}
ggplot(tesla, aes(x = population, y = total)) +
  geom_point() +
  labs(title = "Population vs. Total Number of Chargers",
       x = "Population (2022)",
       y = "Total Number of Chargers")
```

```{r}
data_long <- tesla %>%
  pivot_longer(cols = starts_with("no_"), names_to = "charger_type", values_to = "count")

ggplot(data_long, aes(x = city, y = count, fill = charger_type)) +
  geom_bar(stat = "identity", position = "stack") +
  labs(title = "Number of Different Types of Chargers by City",
       x = "City",
       y = "Count",
       fill = "Charger Type") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}
ggplot(tesla, aes(x = city, y = mile)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(title = "Number of Tesla Supercharger Stations within One Mile of a Highway by City",
       x = "City",
       y = "Number of Stations")
```

```{r}
ggplot(tesla, aes(fill=county, y=population, x=no_stations)) + 
    geom_bar(position="stack", stat="identity")
```

```{r}
ggplot(tesla, aes(x=population, y=no_stations, col=county))+
  geom_point() 
```








```{r}
tesla_model <- tesla %>%
  select_if(is.numeric) %>%
  select(-no_v4)


tesla_model %>%  # none of our cities contain a v4 charger
  cor() %>%
  corrplot.mixed()
```

# Model Building

We will be removing the following variables: `city`, `mile`, `more_than_12`, `no_v2`, `no_urban`, `no_v3`, `no_v4`, and total. We are doing this because we want to build a model that can predict the no_stations based on demographic data of each observation. This updated data set will be called `tesla_model`

```{r}
tesla_model <- tesla %>%
  select(-city) %>%
  select(-mile) %>%
  select(-more_than_12) %>%
  select(-no_v2) %>%
  select(-no_urban) %>%
  select(-no_v3) %>%
  select(-no_v4) %>%
  select(-total)

head(tesla_model)
```

## Data Split

We will first begin with splitting out data into training and testing data. The purpose of doing so is to build and train our predictive model on our training data and test the model on unseen data (the testing data). For this project, we will be using a 70/30 training to testing split.

```{r}
tesla_split <- initial_split(tesla_model, prop = 0.7, strata = no_stations)
tesla_train <- training(tesla_split)
tesla_test <- testing(tesla_split)
```

## Recipe

```{r}
tesla_recipe <- recipe(no_stations ~  county + population + land_size + 
                         medium_income + per_capita_income + registered_voter +
                         democratic + republican, data = tesla_train) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors()) 
```

## Model

```{r}
tesla_folds <- vfold_cv(tesla_train, v = 5, strata = no_stations)
```

1. Setting up the model
```{r}
# Linear Model
lm_model <- linear_reg() %>% 
  set_engine("lm")

# KNN
knn_model <- nearest_neighbor(neighbors = tune()) %>%
  set_engine("kknn") %>%
  set_mode("regression")

# Random Forest
random_forest_model <- rand_forest(mtry=tune(),
                                 trees = tune(),
                                 min_n = tune()) %>%
  set_engine("ranger") %>%
  set_mode("regression")

# Elastic Net
elastic_model <- linear_reg(mixture = tune(), 
    penalty = tune()) %>%
  set_mode("regression") %>%
  set_engine("glmnet")

# Boosted Tree
boosted_tree_model <- boost_tree(mtry = tune(), 
                           trees = tune(), 
                           learn_rate = tune()) %>%
  set_engine("xgboost") %>% 
  set_mode("regression")
```

2. Creating Workflow
```{r}
# Linear Model
lm_workflow <- workflow() %>% 
  add_model(lm_model) %>% 
  add_recipe(tesla_recipe)

# KNN
knn_workflow <- workflow() %>% 
  add_model(knn_model) %>% 
  add_recipe(tesla_recipe)

# Random Forest
random_forest_workflow <- workflow() %>%
  add_model(random_forest_model) %>%
  add_recipe(tesla_recipe)

# Boosted Tree
boosted_tree_workflow <- workflow() %>% 
  add_model(boosted_tree_model) %>% 
  add_recipe(tesla_recipe)

```

3. Creating Grid
```{r}
# KNN
knn_grid <- grid_regular(neighbors(range = c(1,10)), levels = 10)

# Random Forest
rf_grid <- grid_regular(mtry(range = c(1, 6)), 
                        trees(range = c(200, 600)),
                        min_n(range = c(10, 20)),
                        levels = 5)

# Boosted Tree
bt_grid <- grid_regular(mtry(range = c(1, 6)), 
                        trees(range = c(200, 600)),
                        learn_rate(range = c(-10, -1)),
                        levels = 5)

```

4. Tune Model
```{r}
# KNN 
knn_tune <- tune_grid(knn_workflow, resamples = tesla_folds, grid = knn_grid)

# Random Forest
tune_rf <- tune_grid(
  object = random_forest_workflow, resamples = tesla_folds, grid = rf_grid)

# Boosted Tree
bt_tune <- tune_grid(boosted_tree_workflow, resamples = tesla_folds, grid = bt_grid)

```

5. Collect metrics
```{r}
# Linear Model
lm_fit <- fit_resamples(lm_workflow, resamples = tesla_folds)
lm_rmse <- collect_metrics(lm_fit)

# KNN
knn_rmse <- collect_metrics(knn_tune) %>%
  filter(.metric=='rmse')%>%
  arrange(mean)

# Random Forest
rf_rmse <- collect_metrics(tune_rf) %>%
  filter(.metric=='rmse') %>%
  arrange(mean)

# Boosted Tree
bt_rms <- collect_metrics(bt_tune) %>%
  filter(.metric=='rmse') %>%
  arrange(mean)

lm_rmse
knn_rmse
rf_rmse
bt_rms
```

5. Fitting the model
```{r}
# KNN
knn_final <- finalize_workflow(knn_workflow, select_best(knn_tune))
knn_final
knn_final_fit <- fit(knn_final, tesla_train)
knn_final_fit

# Boosted Tree
final_rf_model <- finalize_workflow(rf_reg_wf, best_rf_reg)
final_rf_model <- fit(final_rf_model, wage_train)
```
